# üöÄ Validation System Deployment & Operations Guide

This guide covers production deployment, monitoring, operations, and maintenance of the wrapper validation system.

---

## üìã Pre-Deployment Checklist

### System Requirements
- [ ] **Python 3.8+** with Poetry package management
- [ ] **PIL/Pillow** for image processing (included in dependencies)
- [ ] **Sufficient disk space** for validation logs (if enabled)
- [ ] **Memory**: ~50MB additional per validation process
- [ ] **CPU**: Validation adds ~5-10% overhead

### Code Integration Checklist
- [ ] **Validation system imported** in all wrapper classes
- [ ] **Configuration selected** for production environment
- [ ] **Error handling tested** for all failure scenarios
- [ ] **Performance benchmarked** on representative workloads
- [ ] **Monitoring configured** for validation metrics

---

## üè≠ Production Deployment Strategies

### Strategy 1: Gradual Rollout

**Phase 1: Shadow Mode (Week 1-2)**
```python
# Enable validation but don't act on results
SHADOW_CONFIG = ValidationConfig(
    ENABLE_WRAPPER_VALIDATION=True,
    LOG_VALIDATION_FAILURES=True,       # Log everything
    FAIL_ON_VALIDATION_ERROR=False      # Never break production
)

# Monitor logs for validation patterns without impact
```

**Phase 2: Alert Mode (Week 3-4)**
```python
# Add alerting on validation failures
def production_wrapper_with_alerting():
    result = wrapper.apply(input_path, output_path, params)
    
    if not result.get("validation_passed", True):
        # Send alert but continue processing
        send_validation_alert(result["validations"])
    
    return result
```

**Phase 3: Full Production (Week 5+)**
```python
# Production configuration with operational procedures
PRODUCTION_CONFIG = ValidationConfig(
    ENABLE_WRAPPER_VALIDATION=True,
    LOG_VALIDATION_FAILURES=False,      # Minimize I/O overhead
    FRAME_RATIO_TOLERANCE=0.1,          # Relaxed for stability
    COLOR_COUNT_TOLERANCE=5,            # Permissive for production
    MAX_FILE_SIZE_MB=10.0               # Performance limit
)
```

### Strategy 2: A/B Testing Deployment

```python
import random

class ABTestValidationWrapper:
    def __init__(self, validation_percentage: float = 0.1):
        self.validation_percentage = validation_percentage
        self.control_config = ValidationConfig(ENABLE_WRAPPER_VALIDATION=False)
        self.test_config = ValidationConfig(
            ENABLE_WRAPPER_VALIDATION=True,
            LOG_VALIDATION_FAILURES=True
        )
    
    def apply(self, input_path, output_path, params):
        # Route percentage of traffic to validation
        use_validation = random.random() < self.validation_percentage
        config = self.test_config if use_validation else self.control_config
        
        result = self._compress(input_path, output_path, params)
        
        if use_validation:
            return add_validation_to_result(
                input_path, output_path, params, result,
                config=config
            )
        else:
            return result
```

### Strategy 3: Blue-Green Deployment

```python
# Blue environment: Current production (no validation)
# Green environment: New version (with validation)

class EnvironmentAwareWrapper:
    def __init__(self):
        self.environment = os.getenv("DEPLOYMENT_ENV", "blue")
        
        if self.environment == "green":
            self.config = ValidationConfig(
                ENABLE_WRAPPER_VALIDATION=True,
                LOG_VALIDATION_FAILURES=True
            )
        else:
            self.config = ValidationConfig(
                ENABLE_WRAPPER_VALIDATION=False
            )
    
    def apply(self, input_path, output_path, params):
        result = self._compress(input_path, output_path, params)
        return add_validation_to_result(
            input_path, output_path, params, result,
            config=self.config
        )
```

---

## üìä Production Monitoring

### Key Metrics to Monitor

#### 1. Validation Performance Metrics
```python
import time
import logging
from collections import defaultdict

class ValidationMetricsCollector:
    def __init__(self):
        self.metrics = defaultdict(list)
        self.logger = logging.getLogger("validation.metrics")
    
    def record_validation(self, validation_time: float, file_size: int, 
                         validation_passed: bool, validation_count: int):
        """Record validation performance metrics."""
        
        self.metrics['validation_times'].append(validation_time)
        self.metrics['file_sizes'].append(file_size)
        self.metrics['success_rate'].append(validation_passed)
        
        # Log performance alerts
        if validation_time > 100:  # >100ms is slow
            self.logger.warning(f"Slow validation: {validation_time:.1f}ms for {file_size} byte file")
        
        if validation_count > 10:  # Many validations per file
            self.logger.info(f"Complex validation: {validation_count} checks for file")
    
    def get_hourly_summary(self):
        """Generate hourly performance summary."""
        if not self.metrics['validation_times']:
            return {}
        
        times = self.metrics['validation_times']
        success_rate = sum(self.metrics['success_rate']) / len(self.metrics['success_rate'])
        
        return {
            'avg_validation_time_ms': sum(times) / len(times),
            'max_validation_time_ms': max(times),
            'validation_success_rate': success_rate,
            'total_validations': len(times)
        }
```

#### 2. Validation Failure Monitoring
```python
class ValidationFailureMonitor:
    def __init__(self, alert_threshold: float = 0.05):
        self.alert_threshold = alert_threshold  # 5% failure rate alert
        self.failure_counts = defaultdict(int)
        self.total_operations = 0
    
    def record_operation(self, result: dict):
        """Record validation results for monitoring."""
        self.total_operations += 1
        
        if not result.get("validation_passed", True):
            # Track failure types
            for validation in result.get("validations", []):
                if not validation["is_valid"]:
                    failure_type = validation["validation_type"]
                    self.failure_counts[failure_type] += 1
        
        # Check for alert conditions
        if self.total_operations % 100 == 0:  # Check every 100 operations
            self._check_failure_rates()
    
    def _check_failure_rates(self):
        """Check if failure rates exceed thresholds."""
        for failure_type, count in self.failure_counts.items():
            failure_rate = count / self.total_operations
            
            if failure_rate > self.alert_threshold:
                self._send_alert(f"High {failure_type} failure rate: {failure_rate:.1%}")
    
    def _send_alert(self, message: str):
        # Integration with your alerting system
        logging.error(f"VALIDATION_ALERT: {message}")
```

### 3. System Health Monitoring

```python
class ValidationHealthChecker:
    def __init__(self):
        self.health_metrics = {
            'last_successful_validation': None,
            'consecutive_failures': 0,
            'memory_usage_mb': 0,
            'validation_enabled': True
        }
    
    def health_check(self) -> dict:
        """Comprehensive health check for validation system."""
        
        health_status = {
            'status': 'healthy',
            'issues': [],
            'metrics': self.health_metrics.copy()
        }
        
        # Check if validations are running
        if not self.health_metrics['validation_enabled']:
            health_status['issues'].append('Validation system disabled')
            health_status['status'] = 'degraded'
        
        # Check for consecutive failures
        if self.health_metrics['consecutive_failures'] > 10:
            health_status['issues'].append(f"High consecutive failures: {self.health_metrics['consecutive_failures']}")
            health_status['status'] = 'unhealthy'
        
        # Check memory usage
        if self.health_metrics['memory_usage_mb'] > 500:  # 500MB threshold
            health_status['issues'].append(f"High memory usage: {self.health_metrics['memory_usage_mb']}MB")
            health_status['status'] = 'degraded'
        
        return health_status
    
    def update_health(self, validation_successful: bool, memory_mb: float):
        """Update health metrics."""
        if validation_successful:
            self.health_metrics['last_successful_validation'] = time.time()
            self.health_metrics['consecutive_failures'] = 0
        else:
            self.health_metrics['consecutive_failures'] += 1
        
        self.health_metrics['memory_usage_mb'] = memory_mb
```

---

## üö® Alerting and Notifications

### Alert Configuration

```python
import smtplib
from email.mime.text import MimeText
from typing import Dict, List

class ValidationAlertManager:
    def __init__(self, 
                 smtp_host: str = "localhost",
                 alert_recipients: List[str] = None,
                 severity_thresholds: Dict[str, float] = None):
        
        self.smtp_host = smtp_host
        self.alert_recipients = alert_recipients or ["ops@company.com"]
        
        # Default severity thresholds
        self.thresholds = severity_thresholds or {
            'validation_failure_rate': 0.05,    # 5% failure rate
            'slow_validation_rate': 0.1,        # 10% slow validation rate
            'memory_usage_mb': 200,             # 200MB memory usage
            'consecutive_failures': 20          # 20 consecutive failures
        }
    
    def check_and_alert(self, metrics: dict):
        """Check metrics and send alerts if thresholds exceeded."""
        
        alerts = []
        
        # Check failure rate
        if metrics.get('validation_failure_rate', 0) > self.thresholds['validation_failure_rate']:
            alerts.append({
                'severity': 'HIGH',
                'message': f"Validation failure rate {metrics['validation_failure_rate']:.1%} exceeds threshold"
            })
        
        # Check slow validation rate
        if metrics.get('slow_validation_rate', 0) > self.thresholds['slow_validation_rate']:
            alerts.append({
                'severity': 'MEDIUM',
                'message': f"Slow validation rate {metrics['slow_validation_rate']:.1%} exceeds threshold"
            })
        
        # Send alerts
        for alert in alerts:
            self._send_alert(alert['severity'], alert['message'])
    
    def _send_alert(self, severity: str, message: str):
        """Send alert via configured channels."""
        
        # Email alert
        subject = f"[{severity}] GifLab Validation Alert"
        body = f"Validation System Alert\n\nSeverity: {severity}\nMessage: {message}\n\nTime: {time.ctime()}"
        
        try:
            msg = MimeText(body)
            msg['Subject'] = subject
            msg['From'] = "giflab-alerts@company.com"
            msg['To'] = ", ".join(self.alert_recipients)
            
            with smtplib.SMTP(self.smtp_host) as server:
                server.send_message(msg)
                
        except Exception as e:
            logging.error(f"Failed to send alert: {e}")
        
        # Also log locally
        logging.error(f"ALERT [{severity}]: {message}")
```

### Slack/Teams Integration

```python
import requests
import json

class SlackAlertManager:
    def __init__(self, webhook_url: str, channel: str = "#ops"):
        self.webhook_url = webhook_url
        self.channel = channel
    
    def send_validation_alert(self, severity: str, message: str, metrics: dict = None):
        """Send validation alert to Slack."""
        
        color_map = {
            'HIGH': '#FF0000',      # Red
            'MEDIUM': '#FFA500',    # Orange
            'LOW': '#FFFF00'        # Yellow
        }
        
        payload = {
            "channel": self.channel,
            "username": "GifLab Validation Monitor",
            "attachments": [{
                "color": color_map.get(severity, '#808080'),
                "title": f"Validation System Alert - {severity}",
                "text": message,
                "fields": [
                    {
                        "title": "Timestamp",
                        "value": time.ctime(),
                        "short": True
                    }
                ]
            }]
        }
        
        # Add metrics if provided
        if metrics:
            payload["attachments"][0]["fields"].extend([
                {
                    "title": "Validation Success Rate",
                    "value": f"{metrics.get('success_rate', 0):.1%}",
                    "short": True
                },
                {
                    "title": "Avg Validation Time",
                    "value": f"{metrics.get('avg_time_ms', 0):.1f}ms",
                    "short": True
                }
            ])
        
        try:
            response = requests.post(self.webhook_url, json=payload)
            response.raise_for_status()
        except Exception as e:
            logging.error(f"Failed to send Slack alert: {e}")
```

---

## üîß Operational Procedures

### Procedure 1: Emergency Validation Disable

When validation system causes production issues:

```python
# Emergency disable script
def emergency_disable_validation():
    """Emergency procedure to disable validation system."""
    
    import os
    
    # Set environment variable to disable validation
    os.environ['GIFLAB_VALIDATION_EMERGENCY_DISABLE'] = 'true'
    
    # Update configuration
    emergency_config = ValidationConfig(
        ENABLE_WRAPPER_VALIDATION=False,
        LOG_VALIDATION_FAILURES=False
    )
    
    # Log the action
    logging.critical("EMERGENCY: Validation system disabled due to production issue")
    
    return emergency_config

# Usage in wrapper
def apply_with_emergency_check(self, input_path, output_path, params):
    # Check for emergency disable
    if os.getenv('GIFLAB_VALIDATION_EMERGENCY_DISABLE'):
        # Skip validation entirely
        return self._compress(input_path, output_path, params)
    
    # Normal validation flow
    result = self._compress(input_path, output_path, params)
    return validate_wrapper_apply_result(self, input_path, output_path, params, result)
```

### Procedure 2: Validation Performance Recovery

When validation performance degrades:

```python
class PerformanceRecoveryManager:
    def __init__(self):
        self.performance_mode = "normal"
        self.performance_history = []
    
    def check_performance_degradation(self, validation_time_ms: float):
        """Check for performance degradation and adjust config."""
        
        self.performance_history.append(validation_time_ms)
        
        # Keep only recent history
        if len(self.performance_history) > 100:
            self.performance_history = self.performance_history[-100:]
        
        # Calculate average of recent validations
        recent_avg = sum(self.performance_history[-10:]) / min(10, len(self.performance_history))
        
        # Adjust performance mode based on recent performance
        if recent_avg > 200:  # >200ms average
            if self.performance_mode != "emergency":
                self.performance_mode = "emergency"
                logging.warning("Switching to emergency performance mode due to slow validations")
                return self._get_emergency_config()
        
        elif recent_avg > 100:  # >100ms average
            if self.performance_mode != "degraded":
                self.performance_mode = "degraded"
                logging.warning("Switching to degraded performance mode")
                return self._get_degraded_config()
        
        else:  # Normal performance
            if self.performance_mode != "normal":
                self.performance_mode = "normal"
                logging.info("Switching back to normal performance mode")
                return ValidationConfig()  # Default config
        
        return None  # No config change needed
    
    def _get_emergency_config(self):
        """Ultra-fast configuration for emergency situations."""
        return ValidationConfig(
            ENABLE_WRAPPER_VALIDATION=True,
            LOG_VALIDATION_FAILURES=False,
            FRAME_RATIO_TOLERANCE=0.5,          # Very permissive
            COLOR_COUNT_TOLERANCE=50,           # Very permissive
            FPS_TOLERANCE=0.8,                  # Very permissive
            MAX_FILE_SIZE_MB=1.0                # Process small files only
        )
    
    def _get_degraded_config(self):
        """Balanced configuration for degraded performance."""
        return ValidationConfig(
            ENABLE_WRAPPER_VALIDATION=True,
            LOG_VALIDATION_FAILURES=False,
            FRAME_RATIO_TOLERANCE=0.2,          # Relaxed
            COLOR_COUNT_TOLERANCE=10,           # Relaxed
            FPS_TOLERANCE=0.3,                  # Relaxed
            MAX_FILE_SIZE_MB=5.0                # Moderate file size limit
        )
```

### Procedure 3: Validation Failure Investigation

When validation failures spike:

```python
class FailureInvestigator:
    def __init__(self):
        self.failure_patterns = defaultdict(list)
    
    def investigate_failures(self, failed_validations: List[dict]):
        """Analyze validation failures for patterns."""
        
        analysis = {
            'failure_types': defaultdict(int),
            'common_patterns': [],
            'recommended_actions': []
        }
        
        # Count failure types
        for failure in failed_validations:
            failure_type = failure['validation_type']
            analysis['failure_types'][failure_type] += 1
            
            # Store pattern details
            self.failure_patterns[failure_type].append({
                'expected': failure.get('expected'),
                'actual': failure.get('actual'),
                'error_message': failure.get('error_message'),
                'timestamp': time.time()
            })
        
        # Analyze patterns
        self._analyze_patterns(analysis)
        
        return analysis
    
    def _analyze_patterns(self, analysis: dict):
        """Analyze failure patterns and recommend actions."""
        
        failure_types = analysis['failure_types']
        
        # High frame count failures
        if failure_types.get('frame_count', 0) > 10:
            analysis['recommended_actions'].append(
                "Consider increasing FRAME_RATIO_TOLERANCE - many frame count failures"
            )
        
        # High color count failures  
        if failure_types.get('color_count', 0) > 10:
            analysis['recommended_actions'].append(
                "Consider increasing COLOR_COUNT_TOLERANCE - many color count failures"
            )
        
        # Quality validation failures
        if failure_types.get('quality_degradation', 0) > 5:
            analysis['recommended_actions'].append(
                "Investigate quality validation - possible compression issues"
            )
        
        # File integrity failures
        if failure_types.get('file_integrity', 0) > 3:
            analysis['recommended_actions'].append(
                "URGENT: File integrity failures may indicate corruption"
            )
```

---

## üìà Capacity Planning

### Resource Requirements

```python
class ValidationCapacityPlanner:
    def __init__(self):
        self.baseline_metrics = {
            'cpu_overhead_percent': 5,          # 5% CPU overhead
            'memory_per_validation_mb': 2,      # 2MB per validation
            'disk_io_overhead_percent': 8,      # 8% additional I/O
            'validation_time_ms': 25            # 25ms average validation time
        }
    
    def calculate_capacity_requirements(self, 
                                      daily_operations: int,
                                      concurrent_workers: int,
                                      target_availability: float = 0.99):
        """Calculate resource requirements for validation system."""
        
        # Calculate peak hourly load (assume 3x daily average)
        peak_hourly_ops = (daily_operations * 3) / 24
        peak_ops_per_second = peak_hourly_ops / 3600
        
        # Calculate resource requirements
        requirements = {
            # CPU requirements
            'additional_cpu_cores': (peak_ops_per_second * self.baseline_metrics['cpu_overhead_percent'] / 100) / concurrent_workers,
            
            # Memory requirements
            'additional_memory_gb': (concurrent_workers * self.baseline_metrics['memory_per_validation_mb']) / 1024,
            
            # Storage requirements (if logging enabled)
            'daily_log_storage_mb': daily_operations * 0.1,  # ~0.1MB per operation
            
            # Network overhead (minimal)
            'network_overhead_percent': 1,
            
            # Expected performance impact
            'processing_time_increase_percent': self.baseline_metrics['validation_time_ms'] / 500  # Assume 500ms base processing
        }
        
        return requirements
    
    def generate_capacity_plan(self, current_capacity: dict, growth_projections: dict):
        """Generate capacity planning recommendations."""
        
        plan = {
            'current_validation_capacity': self.calculate_capacity_requirements(
                current_capacity['daily_operations'],
                current_capacity['workers']
            ),
            'projected_requirements': {},
            'recommendations': []
        }
        
        # Calculate requirements for different growth scenarios
        for scenario, projection in growth_projections.items():
            plan['projected_requirements'][scenario] = self.calculate_capacity_requirements(
                projection['daily_operations'],
                projection['workers']
            )
        
        # Generate recommendations
        plan['recommendations'].extend([
            "Monitor validation performance metrics continuously",
            "Plan for 20% additional capacity beyond projections",
            "Implement auto-scaling for validation workers",
            "Consider validation sampling for extreme high-volume scenarios"
        ])
        
        return plan
```

---

## üîÑ Rollback Procedures

### Rollback Plan 1: Configuration Rollback

```python
class ConfigurationRollback:
    def __init__(self):
        self.config_history = []
        self.current_config = None
    
    def save_config_checkpoint(self, config: ValidationConfig, description: str):
        """Save configuration checkpoint for rollback."""
        checkpoint = {
            'config': config,
            'timestamp': time.time(),
            'description': description
        }
        self.config_history.append(checkpoint)
        self.current_config = config
        
        # Keep only last 10 checkpoints
        if len(self.config_history) > 10:
            self.config_history = self.config_history[-10:]
    
    def rollback_to_previous(self) -> ValidationConfig:
        """Rollback to previous configuration."""
        if len(self.config_history) < 2:
            logging.error("No previous configuration available for rollback")
            return self.current_config
        
        # Get previous config (skip current)
        previous_checkpoint = self.config_history[-2]
        
        logging.warning(f"Rolling back configuration to: {previous_checkpoint['description']}")
        return previous_checkpoint['config']
    
    def rollback_to_checkpoint(self, checkpoint_index: int) -> ValidationConfig:
        """Rollback to specific checkpoint."""
        if checkpoint_index >= len(self.config_history):
            logging.error(f"Checkpoint {checkpoint_index} does not exist")
            return self.current_config
        
        checkpoint = self.config_history[checkpoint_index]
        logging.warning(f"Rolling back to checkpoint {checkpoint_index}: {checkpoint['description']}")
        return checkpoint['config']
```

### Rollback Plan 2: Full System Rollback

```python
def execute_validation_rollback():
    """Complete rollback procedure for validation system."""
    
    logging.critical("Executing validation system rollback")
    
    # Step 1: Disable validation immediately
    emergency_config = ValidationConfig(ENABLE_WRAPPER_VALIDATION=False)
    
    # Step 2: Clear any cached validation state
    clear_validation_caches()
    
    # Step 3: Reset performance monitors
    reset_performance_monitors()
    
    # Step 4: Notify operations team
    send_rollback_notification()
    
    # Step 5: Return safe configuration
    return emergency_config

def clear_validation_caches():
    """Clear any cached validation data."""
    # Implementation depends on caching strategy
    pass

def reset_performance_monitors():
    """Reset performance monitoring state."""
    # Implementation depends on monitoring setup
    pass

def send_rollback_notification():
    """Notify operations team of rollback."""
    logging.critical("ROLLBACK EXECUTED: Validation system disabled")
    # Integration with alerting system
```

---

## ‚úÖ Deployment Checklist

### Pre-Production Checklist
- [ ] **Load testing completed** with validation enabled
- [ ] **Performance benchmarks** meet requirements (<10% overhead)
- [ ] **Monitoring dashboards** configured and tested
- [ ] **Alerting thresholds** set and tested
- [ ] **Rollback procedures** documented and tested
- [ ] **Emergency contacts** updated
- [ ] **Configuration management** system updated

### Post-Deployment Checklist
- [ ] **Validation metrics** being collected
- [ ] **Error rates** within expected bounds
- [ ] **Performance impact** within acceptable limits  
- [ ] **Alerts** functioning correctly
- [ ] **Team training** completed on new monitoring/procedures
- [ ] **Documentation** updated with production-specific details

---

## üìö Related Documentation

- [Performance Optimization Guide](../technical/validation-performance-guide.md)
- [Configuration Reference](../reference/validation-config-reference.md)
- [Troubleshooting Guide](validation-troubleshooting.md)
- [Integration Guide](wrapper-validation-integration.md)

---

## üÜò Emergency Contacts

**Validation System Issues**:
- Primary: Development Team
- Secondary: Operations Team  
- Escalation: Engineering Management

**Performance Issues**:
- Primary: Site Reliability Engineering
- Secondary: Infrastructure Team

**Data Integrity Concerns**:  
- Primary: Data Engineering Team
- Secondary: Development Team