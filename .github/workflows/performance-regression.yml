name: Performance Regression Detection

on:
  pull_request:
    paths:
      - 'src/**'
      - 'tests/**'
      - 'pyproject.toml'
      - '.github/workflows/performance-regression.yml'
  push:
    branches:
      - main
      - develop
  schedule:
    # Run weekly performance trend analysis
    - cron: '0 2 * * 1'  # Every Monday at 2 AM UTC
  workflow_dispatch:
    inputs:
      baseline_update:
        description: 'Update performance baselines'
        required: false
        default: 'false'
        type: choice
        options:
          - 'true'
          - 'false'

env:
  PYTHON_VERSION: '3.10'
  POETRY_VERSION: '1.5.1'
  GIFLAB_PERFORMANCE_CI: '1'

jobs:
  performance-regression:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    permissions:
      contents: read
      pull-requests: write
      issues: write
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for commit comparison
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache Poetry installation
      uses: actions/cache@v3
      with:
        path: ~/.local
        key: poetry-${{ env.POETRY_VERSION }}-${{ runner.os }}
    
    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: ${{ env.POETRY_VERSION }}
        virtualenvs-create: true
        virtualenvs-in-project: true
    
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: .venv
        key: venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/poetry.lock') }}
        restore-keys: |
          venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
    
    - name: Install dependencies
      run: |
        poetry install --no-interaction --no-root
        poetry install --no-interaction
    
    - name: Cache performance baselines
      uses: actions/cache@v3
      with:
        path: ~/.giflab/baselines
        key: performance-baselines-${{ runner.os }}-${{ github.ref_name }}
        restore-keys: |
          performance-baselines-${{ runner.os }}-main
          performance-baselines-${{ runner.os }}-
    
    - name: Download latest baselines (if not cached)
      if: github.event_name == 'pull_request'
      run: |
        mkdir -p ~/.giflab/baselines
        # In production, download from S3 or artifact storage
        # For now, use cached baselines or establish new ones
        if [ ! -f ~/.giflab/baselines/current_baselines.json ]; then
          echo "No baselines found, will establish during test"
        fi
    
    - name: Run performance regression tests
      id: regression_test
      run: |
        set +e  # Don't exit on test failure
        poetry run python -m giflab.benchmarks.regression_suite test --tags ci quick > performance_report.txt 2>&1
        TEST_EXIT_CODE=$?
        
        # Capture report for PR comment
        if [ -f benchmark_results/ci_report_*.json ]; then
          REPORT_FILE=$(ls -t benchmark_results/ci_report_*.json | head -1)
          echo "report_file=$REPORT_FILE" >> $GITHUB_OUTPUT
          
          # Extract summary for output
          python -c "
import json
with open('$REPORT_FILE') as f:
    report = json.load(f)
    print(f\"scenarios_run={report['scenarios_run']}\")
    print(f\"scenarios_passed={report['scenarios_passed']}\")
    print(f\"has_regressions={report['has_regressions']}\")
          " >> $GITHUB_OUTPUT
        fi
        
        exit $TEST_EXIT_CODE
      continue-on-error: true
    
    - name: Update baselines (if requested)
      if: github.event.inputs.baseline_update == 'true' || (github.event_name == 'push' && github.ref == 'refs/heads/main')
      run: |
        poetry run python -m giflab.benchmarks.regression_suite baseline --tags ci
        
        # Upload new baselines as artifact
        if [ -f ~/.giflab/baselines/current_baselines.json ]; then
          echo "Baselines updated for commit ${{ github.sha }}"
        fi
    
    - name: Generate performance report
      if: always()
      id: generate_report
      run: |
        python scripts/generate_performance_report.py \
          --report-file "${{ steps.regression_test.outputs.report_file }}" \
          --output-format markdown \
          > performance_report.md
        
        # Also generate HTML report for artifact
        python scripts/generate_performance_report.py \
          --report-file "${{ steps.regression_test.outputs.report_file }}" \
          --output-format html \
          > performance_report.html
    
    - name: Comment on PR with results
      if: github.event_name == 'pull_request' && always()
      uses: actions/github-script@v7
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('performance_report.md', 'utf8');
          
          // Find and update existing comment or create new one
          const { data: comments } = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
          });
          
          const botComment = comments.find(comment => 
            comment.user.type === 'Bot' && 
            comment.body.includes('## üìä Performance Regression Report')
          );
          
          const body = `## üìä Performance Regression Report\n\n${report}\n\n---\n*Generated at ${new Date().toISOString()}*`;
          
          if (botComment) {
            await github.rest.issues.updateComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: botComment.id,
              body: body
            });
          } else {
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: body
            });
          }
    
    - name: Upload performance artifacts
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: performance-reports-${{ github.sha }}
        path: |
          benchmark_results/
          performance_report.txt
          performance_report.md
          performance_report.html
        retention-days: 30
    
    - name: Check regression test results
      if: steps.regression_test.outcome == 'failure'
      run: |
        echo "‚ùå Performance regression detected!"
        echo "Scenarios run: ${{ steps.regression_test.outputs.scenarios_run }}"
        echo "Scenarios passed: ${{ steps.regression_test.outputs.scenarios_passed }}"
        
        if [ "${{ github.event_name }}" == "pull_request" ]; then
          echo "::error::Critical performance regressions detected. Please review the performance report."
          exit 1
        else
          echo "::warning::Performance regressions detected in main branch"
        fi
    
    - name: Success notification
      if: steps.regression_test.outcome == 'success'
      run: |
        echo "‚úÖ All performance tests passed!"
        echo "No critical regressions detected."

  weekly-performance-trends:
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    needs: performance-regression
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install Poetry and dependencies
      run: |
        pip install poetry==${{ env.POETRY_VERSION }}
        poetry install --no-interaction
    
    - name: Download performance history
      uses: actions/download-artifact@v3
      with:
        name: performance-reports-*
        path: ./performance-history/
    
    - name: Generate trend report
      run: |
        poetry run python scripts/analyze_performance_trends.py \
          --history-dir ./performance-history \
          --output weekly_trend_report.html \
          --format html
        
        poetry run python scripts/analyze_performance_trends.py \
          --history-dir ./performance-history \
          --output weekly_trend_summary.md \
          --format markdown
    
    - name: Create issue with trend report
      if: github.event_name == 'schedule'
      uses: actions/github-script@v7
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const fs = require('fs');
          const summary = fs.readFileSync('weekly_trend_summary.md', 'utf8');
          
          const date = new Date().toISOString().split('T')[0];
          const title = `üìà Weekly Performance Trend Report - ${date}`;
          
          await github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: title,
            body: summary,
            labels: ['performance', 'automated-report']
          });
    
    - name: Upload trend reports
      uses: actions/upload-artifact@v3
      with:
        name: weekly-performance-trends-${{ github.run_id }}
        path: |
          weekly_trend_report.html
          weekly_trend_summary.md
        retention-days: 90