{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üéûÔ∏è GifLab Dataset Exploration - Beginner's Guide\n",
        "\n",
        "**A step-by-step guide to analyzing your GIF dataset and optimizing compression strategies**\n",
        "\n",
        "## üëã Welcome! This notebook will guide you through:\n",
        "\n",
        "### **What You'll Learn:**\n",
        "1. **How to analyze your GIF collection** - Understand what types of GIFs you have\n",
        "2. **How to identify optimization opportunities** - Find ways to make compression faster\n",
        "3. **How to make data-driven decisions** - Use real data instead of guessing\n",
        "4. **How to prepare for efficient processing** - Set up your pipeline for success\n",
        "\n",
        "### **What You'll Need:**\n",
        "- **GIF files** in your `data/raw/` directory (we'll help you check this)\n",
        "- **About 10-30 minutes** to run through this notebook\n",
        "- **No prior experience required** - we'll explain everything!\n",
        "\n",
        "### **What You'll Get:**\n",
        "- **Detailed insights** about your GIF collection\n",
        "- **Optimization recommendations** to make processing faster\n",
        "- **Data files** that will speed up your compression pipeline\n",
        "- **Clear next steps** for processing your GIFs\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Step-by-Step Guide\n",
        "\n",
        "### **Step 1:** [Setup & Check Your Environment](#setup)\n",
        "*We'll make sure everything is working and find your GIF files*\n",
        "\n",
        "### **Step 2:** [Explore Your GIF Collection](#overview)  \n",
        "*Discover what types of GIFs you have and check for any problems*\n",
        "\n",
        "### **Step 3:** [Analyze Individual Characteristics](#univariate)\n",
        "*Look at file sizes, dimensions, frame counts, and more*\n",
        "\n",
        "### **Step 4:** [Find Relationships Between Properties](#bivariate)\n",
        "*See how different GIF properties relate to each other*\n",
        "\n",
        "### **Step 5:** [Group Similar GIFs Together](#multivariate)\n",
        "*Organize your GIFs into categories for better processing*\n",
        "\n",
        "### **Step 6:** [Get Smart Recommendations](#advanced)\n",
        "*Learn which compression settings work best for your GIFs*\n",
        "\n",
        "### **Step 7:** [Summary and Next Steps](#insights)\n",
        "*Get your final recommendations and learn what to do next*\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Ready to Start?\n",
        "\n",
        "**Don't worry if you're new to this!** Each section will:\n",
        "- ‚úÖ Explain what we're doing and why\n",
        "- ‚úÖ Show you the results with clear visualizations  \n",
        "- ‚úÖ Give you actionable insights you can use\n",
        "- ‚úÖ Guide you to the next step\n",
        "\n",
        "**Let's begin by setting up your environment!** üëá\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 1: Setup & Check Your Environment <a id=\"setup\"></a>\n",
        "\n",
        "### üîß What We're Doing Here:\n",
        "This step sets up all the tools we need to analyze your GIFs. Think of it like getting your toolbox ready before starting a project.\n",
        "\n",
        "### üìö What This Code Does:\n",
        "- **Imports libraries** - Like getting different tools from your toolbox\n",
        "- **Sets up visualization** - So we can create charts and graphs\n",
        "- **Configures the analysis** - Sets some basic settings\n",
        "- **Checks versions** - Makes sure everything is compatible\n",
        "\n",
        "### üöÄ Just Run This Cell:\n",
        "*Don't worry about understanding every line - just run it and we'll explain what happens!*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üöÄ Setting up your GIF analysis environment...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Standard data analysis tools\n",
        "import pandas as pd  # For working with data tables\n",
        "import numpy as np   # For mathematical calculations\n",
        "import matplotlib.pyplot as plt  # For creating charts\n",
        "import seaborn as sns  # For beautiful statistical plots\n",
        "import plotly.express as px  # For interactive charts\n",
        "import plotly.graph_objects as go  # For advanced interactive plots\n",
        "from pathlib import Path  # For working with file paths\n",
        "from datetime import datetime  # For timestamps\n",
        "import warnings\n",
        "import json\n",
        "import random\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "from tqdm import tqdm  # For progress bars\n",
        "warnings.filterwarnings('ignore')  # Hide technical warnings\n",
        "\n",
        "print(\"‚úÖ Standard analysis tools loaded\")\n",
        "\n",
        "# GifLab specific tools\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "try:\n",
        "    from giflab import meta, metrics, config\n",
        "    from giflab.meta import extract_gif_metadata, GifMetadata\n",
        "    from giflab.pipeline import CompressionPipeline\n",
        "    print(\"‚úÖ GifLab tools loaded successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ö†Ô∏è  Warning: Some GifLab tools couldn't be loaded: {e}\")\n",
        "    print(\"   This might be okay - we'll create sample data if needed\")\n",
        "\n",
        "# Set random seeds for reproducible results\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "print(\"‚úÖ Random seed set for reproducible results\")\n",
        "\n",
        "# Configure visualization settings\n",
        "plt.style.use('seaborn-v0_8')\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.float_format', '{:.3f}'.format)\n",
        "print(\"‚úÖ Visualization settings configured\")\n",
        "\n",
        "# Analysis configuration - you can change these if needed!\n",
        "ANALYSIS_CONFIG = {\n",
        "    'sample_size': 1000,  # How many GIFs to analyze (start with 1000)\n",
        "    'random_seed': 42,    # For reproducible results\n",
        "    'figure_size': (12, 8),  # Size of charts\n",
        "    'color_palette': 'viridis',  # Color scheme for charts\n",
        "    'statistical_threshold': 0.05  # For statistical tests\n",
        "}\n",
        "\n",
        "print(\"\\nüìä GifLab Dataset Exploration - Ready to Go!\")\n",
        "print(f\"üîß Analysis Configuration:\")\n",
        "for key, value in ANALYSIS_CONFIG.items():\n",
        "    print(f\"   ‚Ä¢ {key}: {value}\")\n",
        "\n",
        "print(f\"\\nüì¶ Tool Versions:\")\n",
        "print(f\"   ‚Ä¢ Pandas: {pd.__version__}\")\n",
        "print(f\"   ‚Ä¢ NumPy: {np.__version__}\")\n",
        "print(f\"   ‚Ä¢ Matplotlib: {plt.matplotlib.__version__}\")\n",
        "print(f\"   ‚Ä¢ Seaborn: {sns.__version__}\")\n",
        "\n",
        "print(f\"\\nüéâ Everything is set up! Ready to analyze your GIFs!\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 2: Explore Your GIF Collection <a id=\"overview\"></a>\n",
        "\n",
        "### üîç What We're Doing Now:\n",
        "We're going to look through your GIF files and gather basic information about them. This is like doing an inventory of what you have.\n",
        "\n",
        "### üí° Why This Matters:\n",
        "- **Find problems early** - Detect corrupted or unreadable GIF files\n",
        "- **Understand your collection** - See how many GIFs you have and their basic properties\n",
        "- **Plan processing** - Know what we're working with before we start\n",
        "\n",
        "### üìÅ Where We Look:\n",
        "We'll search in your `data/raw/` directory for GIF files. If you don't have any GIFs there yet, don't worry - we'll show you what to do!\n",
        "\n",
        "### üéØ What You'll See:\n",
        "- How many GIF files were found\n",
        "- How many are readable vs. corrupted\n",
        "- Basic file information\n",
        "- A sample of your GIF data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üîç Step 2: Exploring Your GIF Collection\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "def scan_gif_directory(raw_dir: Path, max_files: Optional[int] = None) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Scan directory and collect basic information about GIF files.\n",
        "    \n",
        "    Args:\n",
        "        raw_dir: Path to directory containing raw GIF files\n",
        "        max_files: Maximum number of files to process (for sampling)\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary containing file information and basic statistics\n",
        "    \"\"\"\n",
        "    print(f\"üîç Scanning directory: {raw_dir}\")\n",
        "    \n",
        "    # Find all GIF files\n",
        "    gif_files = list(raw_dir.rglob(\"*.gif\"))\n",
        "    total_files = len(gif_files)\n",
        "    \n",
        "    print(f\"üìÅ Found {total_files} GIF files\")\n",
        "    \n",
        "    # Sample files if requested\n",
        "    if max_files and max_files < total_files:\n",
        "        gif_files = random.sample(gif_files, max_files)\n",
        "        print(f\"üìä Sampling {max_files} files for analysis\")\n",
        "    \n",
        "    # Collect file information\n",
        "    file_info = []\n",
        "    corrupted_files = []\n",
        "    \n",
        "    for gif_path in tqdm(gif_files, desc=\"Analyzing files\"):\n",
        "        try:\n",
        "            # Get basic file info\n",
        "            stat = gif_path.stat()\n",
        "            file_size_kb = stat.st_size / 1024.0\n",
        "            \n",
        "            # Try to extract metadata\n",
        "            try:\n",
        "                metadata = extract_gif_metadata(gif_path)\n",
        "                file_info.append({\n",
        "                    'path': gif_path,\n",
        "                    'relative_path': gif_path.relative_to(raw_dir),\n",
        "                    'file_size_kb': file_size_kb,\n",
        "                    'metadata': metadata,\n",
        "                    'valid': True\n",
        "                })\n",
        "            except Exception as meta_error:\n",
        "                # File exists but metadata extraction failed\n",
        "                corrupted_files.append({\n",
        "                    'path': gif_path,\n",
        "                    'relative_path': gif_path.relative_to(raw_dir),\n",
        "                    'file_size_kb': file_size_kb,\n",
        "                    'error': str(meta_error),\n",
        "                    'valid': False\n",
        "                })\n",
        "                \n",
        "        except Exception as file_error:\n",
        "            print(f\"‚ö†Ô∏è  Error accessing {gif_path}: {file_error}\")\n",
        "    \n",
        "    return {\n",
        "        'total_files_found': total_files,\n",
        "        'files_analyzed': len(gif_files),\n",
        "        'valid_gifs': file_info,\n",
        "        'corrupted_gifs': corrupted_files,\n",
        "        'success_rate': len(file_info) / len(gif_files) if gif_files else 0\n",
        "    }\n",
        "\n",
        "# Set up paths\n",
        "raw_dir = Path(\"../data/raw\")\n",
        "if not raw_dir.exists():\n",
        "    print(f\"‚ö†Ô∏è  Raw data directory not found: {raw_dir}\")\n",
        "    print(\"Creating example directory structure...\")\n",
        "    raw_dir.mkdir(parents=True, exist_ok=True)\n",
        "    print(\"üìÅ Please add GIF files to the data/raw/ directory\")\n",
        "    \n",
        "    # Create a sample result for demonstration\n",
        "    scan_results = {\n",
        "        'total_files_found': 0,\n",
        "        'files_analyzed': 0,\n",
        "        'valid_gifs': [],\n",
        "        'corrupted_gifs': [],\n",
        "        'success_rate': 0\n",
        "    }\n",
        "else:\n",
        "    # Scan the directory\n",
        "    scan_results = scan_gif_directory(raw_dir, max_files=ANALYSIS_CONFIG['sample_size'])\n",
        "\n",
        "print(f\"\\nüìä Scan Results:\")\n",
        "print(f\"   ‚Ä¢ Total files found: {scan_results['total_files_found']}\")\n",
        "print(f\"   ‚Ä¢ Files analyzed: {scan_results['files_analyzed']}\")\n",
        "print(f\"   ‚Ä¢ Valid GIFs: {len(scan_results['valid_gifs'])}\")\n",
        "print(f\"   ‚Ä¢ Corrupted files: {len(scan_results['corrupted_gifs'])}\")\n",
        "print(f\"   ‚Ä¢ Success rate: {scan_results['success_rate']:.1%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nüìä Converting Your GIF Data to Analysis Format\")\n",
        "print(\"-\" * 40)\n",
        "print(\"Now we'll organize the GIF information into a table for easy analysis...\")\n",
        "\n",
        "def create_metadata_dataframe(scan_results: Dict[str, Any]) -> pd.DataFrame:\n",
        "    \"\"\"Convert scan results to a pandas DataFrame for analysis.\"\"\"\n",
        "    \n",
        "    if not scan_results['valid_gifs']:\n",
        "        print(\"‚ö†Ô∏è  No valid GIFs found. Creating empty DataFrame with expected columns.\")\n",
        "        print(\"   üí° To fix this: Add some .gif files to your data/raw/ directory\")\n",
        "        return pd.DataFrame(columns=[\n",
        "            'gif_sha', 'orig_filename', 'orig_kilobytes', 'orig_width', 'orig_height',\n",
        "            'orig_frames', 'orig_fps', 'orig_n_colors', 'entropy', 'file_size_kb',\n",
        "            'aspect_ratio', 'duration_seconds', 'pixels_total'\n",
        "        ])\n",
        "    \n",
        "    print(f\"‚úÖ Processing {len(scan_results['valid_gifs'])} valid GIFs...\")\n",
        "    \n",
        "    records = []\n",
        "    for gif_info in scan_results['valid_gifs']:\n",
        "        metadata = gif_info['metadata']\n",
        "        \n",
        "        # Calculate some useful extra information\n",
        "        aspect_ratio = metadata.orig_width / metadata.orig_height if metadata.orig_height > 0 else 0\n",
        "        duration_seconds = metadata.orig_frames / metadata.orig_fps if metadata.orig_fps > 0 else 0\n",
        "        pixels_total = metadata.orig_width * metadata.orig_height\n",
        "        \n",
        "        record = {\n",
        "            'gif_sha': metadata.gif_sha,  # Unique identifier for this GIF\n",
        "            'orig_filename': metadata.orig_filename,  # Original file name\n",
        "            'orig_kilobytes': metadata.orig_kilobytes,  # File size in KB\n",
        "            'orig_width': metadata.orig_width,  # Width in pixels\n",
        "            'orig_height': metadata.orig_height,  # Height in pixels\n",
        "            'orig_frames': metadata.orig_frames,  # Number of animation frames\n",
        "            'orig_fps': metadata.orig_fps,  # Frames per second\n",
        "            'orig_n_colors': metadata.orig_n_colors,  # Number of colors used\n",
        "            'entropy': metadata.entropy,  # Complexity measure\n",
        "            'file_size_kb': gif_info['file_size_kb'],  # Actual file size\n",
        "            'aspect_ratio': aspect_ratio,  # Width/height ratio\n",
        "            'duration_seconds': duration_seconds,  # How long the animation lasts\n",
        "            'pixels_total': pixels_total  # Total number of pixels\n",
        "        }\n",
        "        records.append(record)\n",
        "    \n",
        "    df = pd.DataFrame(records)\n",
        "    print(f\"‚úÖ Created analysis table with {len(df)} GIFs and {len(df.columns)} properties\")\n",
        "    return df\n",
        "\n",
        "# Create the analysis table\n",
        "gif_df = create_metadata_dataframe(scan_results)\n",
        "\n",
        "if not gif_df.empty:\n",
        "    print(f\"\\nüìà Your GIF Collection Summary:\")\n",
        "    print(f\"   ‚Ä¢ Total GIFs: {len(gif_df)}\")\n",
        "    print(f\"   ‚Ä¢ Properties tracked: {len(gif_df.columns)}\")\n",
        "    \n",
        "    print(f\"\\nüìã Properties We're Tracking:\")\n",
        "    property_descriptions = {\n",
        "        'orig_filename': 'Original file name',\n",
        "        'orig_kilobytes': 'File size (KB)',\n",
        "        'orig_width': 'Width (pixels)',\n",
        "        'orig_height': 'Height (pixels)',\n",
        "        'orig_frames': 'Number of frames',\n",
        "        'orig_fps': 'Frames per second',\n",
        "        'orig_n_colors': 'Number of colors',\n",
        "        'entropy': 'Complexity score',\n",
        "        'aspect_ratio': 'Width/height ratio',\n",
        "        'duration_seconds': 'Animation length',\n",
        "        'pixels_total': 'Total pixels'\n",
        "    }\n",
        "    \n",
        "    for prop, desc in property_descriptions.items():\n",
        "        if prop in gif_df.columns:\n",
        "            print(f\"   ‚Ä¢ {prop}: {desc}\")\n",
        "    \n",
        "    print(f\"\\nüîç Sample of Your GIF Data:\")\n",
        "    print(\"Here are the first few GIFs in your collection:\")\n",
        "    display(gif_df.head())\n",
        "    \n",
        "    print(f\"\\nüí° What This Means:\")\n",
        "    print(\"   ‚Ä¢ Each row represents one GIF file\")\n",
        "    print(\"   ‚Ä¢ Each column shows a different property of that GIF\")\n",
        "    print(\"   ‚Ä¢ We'll use this data to find patterns and optimize compression\")\n",
        "    \n",
        "else:\n",
        "    print(\"\\nüìù No GIF Data Available\")\n",
        "    print(\"=\" * 30)\n",
        "    print(\"It looks like we couldn't find any GIF files to analyze.\")\n",
        "    print(\"\\nüîß To get started:\")\n",
        "    print(\"   1. Create a 'data' folder in your project directory\")\n",
        "    print(\"   2. Create a 'raw' folder inside the 'data' folder\")\n",
        "    print(\"   3. Add some .gif files to the 'data/raw/' directory\")\n",
        "    print(\"   4. Re-run this notebook\")\n",
        "    print(\"\\nüìÅ Expected directory structure:\")\n",
        "    print(\"   your-project/\")\n",
        "    print(\"   ‚îú‚îÄ‚îÄ data/\")\n",
        "    print(\"   ‚îÇ   ‚îî‚îÄ‚îÄ raw/\")\n",
        "    print(\"   ‚îÇ       ‚îú‚îÄ‚îÄ your-gif-1.gif\")\n",
        "    print(\"   ‚îÇ       ‚îú‚îÄ‚îÄ your-gif-2.gif\")\n",
        "    print(\"   ‚îÇ       ‚îî‚îÄ‚îÄ ...\")\n",
        "    print(\"   ‚îî‚îÄ‚îÄ notebooks/\")\n",
        "    print(\"       ‚îî‚îÄ‚îÄ 01_explore_dataset.ipynb (this file)\")\n",
        "    \n",
        "    # Create sample data for demonstration\n",
        "    print(\"\\nüé≠ Creating Sample Data for Demonstration\")\n",
        "    print(\"Since no real GIFs were found, we'll create some example data so you can see how the analysis works...\")\n",
        "    \n",
        "    sample_data = {\n",
        "        'gif_sha': ['abc123', 'def456', 'ghi789'],\n",
        "        'orig_filename': ['sample1.gif', 'sample2.gif', 'sample3.gif'],\n",
        "        'orig_kilobytes': [245.5, 1024.2, 512.8],\n",
        "        'orig_width': [480, 640, 320],\n",
        "        'orig_height': [270, 360, 240],\n",
        "        'orig_frames': [24, 48, 12],\n",
        "        'orig_fps': [15.0, 24.0, 10.0],\n",
        "        'orig_n_colors': [128, 256, 64],\n",
        "        'entropy': [4.2, 5.8, 3.1],\n",
        "        'file_size_kb': [245.5, 1024.2, 512.8],\n",
        "        'aspect_ratio': [1.78, 1.78, 1.33],\n",
        "        'duration_seconds': [1.6, 2.0, 1.2],\n",
        "        'pixels_total': [129600, 230400, 76800]\n",
        "    }\n",
        "    \n",
        "    gif_df = pd.DataFrame(sample_data)\n",
        "    print(f\"‚úÖ Created sample dataset with {len(gif_df)} example GIFs\")\n",
        "    print(\"\\nüîç Sample Data Preview:\")\n",
        "    display(gif_df)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Univariate Analysis <a id=\"univariate\"></a>\n",
        "\n",
        "### Statistical Summary and Distribution Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_statistical_summary(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Generate comprehensive statistical summary including skewness and kurtosis.\"\"\"\n",
        "    if df.empty:\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    # Select numeric columns\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    \n",
        "    if len(numeric_cols) == 0:\n",
        "        print(\"No numeric columns found for statistical analysis\")\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    summary = df[numeric_cols].describe()\n",
        "    summary.loc['skewness'] = df[numeric_cols].skew()\n",
        "    summary.loc['kurtosis'] = df[numeric_cols].kurtosis()\n",
        "    summary.loc['missing'] = df[numeric_cols].isnull().sum()\n",
        "    \n",
        "    return summary.round(3)\n",
        "\n",
        "if not gif_df.empty:\n",
        "    print(\"üìä Comprehensive Statistical Summary\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    stats_summary = generate_statistical_summary(gif_df)\n",
        "    display(stats_summary)\n",
        "    \n",
        "    # Key insights from statistics\n",
        "    print(\"\\nüîç Key Statistical Insights:\")\n",
        "    \n",
        "    if 'orig_kilobytes' in gif_df.columns:\n",
        "        avg_size = gif_df['orig_kilobytes'].mean()\n",
        "        median_size = gif_df['orig_kilobytes'].median()\n",
        "        print(f\"   ‚Ä¢ Average file size: {avg_size:.1f} KB\")\n",
        "        print(f\"   ‚Ä¢ Median file size: {median_size:.1f} KB\")\n",
        "        \n",
        "    if 'orig_frames' in gif_df.columns:\n",
        "        avg_frames = gif_df['orig_frames'].mean()\n",
        "        print(f\"   ‚Ä¢ Average frame count: {avg_frames:.1f}\")\n",
        "        \n",
        "    if 'orig_fps' in gif_df.columns:\n",
        "        avg_fps = gif_df['orig_fps'].mean()\n",
        "        print(f\"   ‚Ä¢ Average FPS: {avg_fps:.1f}\")\n",
        "        \n",
        "    if 'aspect_ratio' in gif_df.columns:\n",
        "        common_ratios = gif_df['aspect_ratio'].round(2).value_counts().head(3)\n",
        "        print(f\"   ‚Ä¢ Most common aspect ratios: {common_ratios.index.tolist()}\")\n",
        "        \n",
        "else:\n",
        "    print(\"üìù No data available for statistical analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution visualizations\n",
        "def create_distribution_plots(df: pd.DataFrame, columns: List[str], title_prefix: str = \"\"):\n",
        "    \"\"\"Create distribution plots for specified columns.\"\"\"\n",
        "    if df.empty:\n",
        "        print(\"No data available for plotting\")\n",
        "        return\n",
        "    \n",
        "    n_cols = len(columns)\n",
        "    if n_cols == 0:\n",
        "        return\n",
        "        \n",
        "    # Calculate subplot layout\n",
        "    n_rows = (n_cols + 2) // 3  # 3 columns per row\n",
        "    n_plot_cols = min(3, n_cols)\n",
        "    \n",
        "    fig, axes = plt.subplots(n_rows, n_plot_cols, figsize=(15, 5 * n_rows))\n",
        "    fig.suptitle(f'{title_prefix} Distributions', fontsize=16, y=0.98)\n",
        "    \n",
        "    # Handle single subplot case\n",
        "    if n_cols == 1:\n",
        "        axes = [axes]\n",
        "    elif n_rows == 1:\n",
        "        axes = axes if n_cols > 1 else [axes]\n",
        "    else:\n",
        "        axes = axes.flatten()\n",
        "    \n",
        "    for i, col in enumerate(columns):\n",
        "        if col in df.columns and not df[col].isnull().all():\n",
        "            # Histogram with KDE\n",
        "            axes[i].hist(df[col].dropna(), bins=30, alpha=0.7, density=True, color='skyblue')\n",
        "            \n",
        "            # Add KDE if data is available\n",
        "            try:\n",
        "                df[col].dropna().plot.kde(ax=axes[i], color='red', linewidth=2)\n",
        "            except:\n",
        "                pass  # Skip KDE if it fails\n",
        "                \n",
        "            axes[i].set_title(f'{col}\\n(mean: {df[col].mean():.2f}, std: {df[col].std():.2f})')\n",
        "            axes[i].set_xlabel(col)\n",
        "            axes[i].set_ylabel('Density')\n",
        "            axes[i].grid(True, alpha=0.3)\n",
        "        else:\n",
        "            axes[i].text(0.5, 0.5, f'No data for {col}', ha='center', va='center', transform=axes[i].transAxes)\n",
        "            axes[i].set_title(f'{col} (No Data)')\n",
        "    \n",
        "    # Hide empty subplots\n",
        "    for i in range(n_cols, len(axes)):\n",
        "        axes[i].set_visible(False)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if not gif_df.empty:\n",
        "    # Dimensional characteristics\n",
        "    dimension_cols = ['orig_width', 'orig_height', 'aspect_ratio', 'pixels_total']\n",
        "    available_dim_cols = [col for col in dimension_cols if col in gif_df.columns]\n",
        "    if available_dim_cols:\n",
        "        create_distribution_plots(gif_df, available_dim_cols, \"Dimensional Characteristics\")\n",
        "    \n",
        "    # Temporal properties  \n",
        "    temporal_cols = ['orig_frames', 'orig_fps', 'duration_seconds']\n",
        "    available_temp_cols = [col for col in temporal_cols if col in gif_df.columns]\n",
        "    if available_temp_cols:\n",
        "        create_distribution_plots(gif_df, available_temp_cols, \"Temporal Properties\")\n",
        "    \n",
        "    # Color and complexity\n",
        "    color_cols = ['orig_n_colors', 'entropy']\n",
        "    available_color_cols = [col for col in color_cols if col in gif_df.columns]\n",
        "    if available_color_cols:\n",
        "        create_distribution_plots(gif_df, available_color_cols, \"Color & Complexity\")\n",
        "    \n",
        "    # File size patterns\n",
        "    size_cols = ['orig_kilobytes']\n",
        "    available_size_cols = [col for col in size_cols if col in gif_df.columns]\n",
        "    if available_size_cols:\n",
        "        create_distribution_plots(gif_df, available_size_cols, \"File Size Patterns\")\n",
        "        \n",
        "else:\n",
        "    print(\"üìù No data available for distribution analysis\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Bivariate Analysis <a id=\"bivariate\"></a>\n",
        "\n",
        "### Correlation Analysis and Relationship Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_correlation_analysis(df: pd.DataFrame):\n",
        "    \"\"\"Create comprehensive correlation analysis.\"\"\"\n",
        "    if df.empty:\n",
        "        print(\"No data available for correlation analysis\")\n",
        "        return\n",
        "    \n",
        "    # Select numeric columns for correlation\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    \n",
        "    if len(numeric_cols) < 2:\n",
        "        print(\"Need at least 2 numeric columns for correlation analysis\")\n",
        "        return\n",
        "    \n",
        "    # Calculate correlation matrix\n",
        "    corr_matrix = df[numeric_cols].corr()\n",
        "    \n",
        "    # Create correlation heatmap\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "    \n",
        "    sns.heatmap(corr_matrix, \n",
        "                mask=mask,\n",
        "                annot=True, \n",
        "                cmap='RdBu_r', \n",
        "                center=0,\n",
        "                square=True,\n",
        "                fmt='.2f',\n",
        "                cbar_kws={'shrink': 0.8})\n",
        "    \n",
        "    plt.title('Correlation Matrix - GIF Characteristics', fontsize=14, pad=20)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Find strongest correlations\n",
        "    print(\"üîç Strongest Correlations (|r| > 0.5):\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # Get upper triangle of correlation matrix\n",
        "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "    \n",
        "    # Find correlations above threshold\n",
        "    strong_corrs = []\n",
        "    for col in upper_tri.columns:\n",
        "        for idx in upper_tri.index:\n",
        "            value = upper_tri.loc[idx, col]\n",
        "            if pd.notna(value) and abs(value) > 0.5:\n",
        "                strong_corrs.append((idx, col, value))\n",
        "    \n",
        "    # Sort by absolute correlation value\n",
        "    strong_corrs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
        "    \n",
        "    if strong_corrs:\n",
        "        for var1, var2, corr_val in strong_corrs:\n",
        "            direction = \"positive\" if corr_val > 0 else \"negative\"\n",
        "            print(f\"   ‚Ä¢ {var1} ‚Üî {var2}: {corr_val:.3f} ({direction})\")\n",
        "    else:\n",
        "        print(\"   ‚Ä¢ No correlations with |r| > 0.5 found\")\n",
        "    \n",
        "    return corr_matrix\n",
        "\n",
        "if not gif_df.empty:\n",
        "    correlation_matrix = create_correlation_analysis(gif_df)\n",
        "else:\n",
        "    print(\"üìù No data available for correlation analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scatter plots for key relationships\n",
        "def create_scatter_plots(df: pd.DataFrame):\n",
        "    \"\"\"Create scatter plots for key relationships.\"\"\"\n",
        "    if df.empty:\n",
        "        print(\"No data available for scatter plots\")\n",
        "        return\n",
        "    \n",
        "    # Define key relationships to explore\n",
        "    relationships = [\n",
        "        ('orig_width', 'orig_height', 'orig_kilobytes'),\n",
        "        ('orig_frames', 'orig_kilobytes', 'orig_fps'),\n",
        "        ('entropy', 'orig_kilobytes', 'orig_n_colors'),\n",
        "        ('pixels_total', 'orig_kilobytes', 'orig_frames')\n",
        "    ]\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    fig.suptitle('Key Relationships in GIF Characteristics', fontsize=16)\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for i, (x_col, y_col, color_col) in enumerate(relationships):\n",
        "        if all(col in df.columns for col in [x_col, y_col, color_col]):\n",
        "            scatter = axes[i].scatter(df[x_col], df[y_col], \n",
        "                                    c=df[color_col], \n",
        "                                    alpha=0.6, \n",
        "                                    cmap='viridis')\n",
        "            axes[i].set_xlabel(x_col)\n",
        "            axes[i].set_ylabel(y_col)\n",
        "            axes[i].set_title(f'{y_col} vs {x_col}\\n(colored by {color_col})')\n",
        "            axes[i].grid(True, alpha=0.3)\n",
        "            \n",
        "            # Add colorbar\n",
        "            plt.colorbar(scatter, ax=axes[i], label=color_col)\n",
        "        else:\n",
        "            axes[i].text(0.5, 0.5, f'Data not available\\nfor {x_col}, {y_col}, {color_col}', \n",
        "                        ha='center', va='center', transform=axes[i].transAxes)\n",
        "            axes[i].set_title(f'{y_col} vs {x_col} (No Data)')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if not gif_df.empty:\n",
        "    create_scatter_plots(gif_df)\n",
        "else:\n",
        "    print(\"üìù No data available for scatter plot analysis\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Multivariate Analysis <a id=\"multivariate\"></a>\n",
        "\n",
        "### Clustering and Pattern Recognition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def perform_clustering_analysis(df: pd.DataFrame, n_clusters: int = 3):\n",
        "    \"\"\"Perform K-means clustering on GIF characteristics.\"\"\"\n",
        "    if df.empty:\n",
        "        print(\"No data available for clustering analysis\")\n",
        "        return None\n",
        "    \n",
        "    # Select features for clustering\n",
        "    feature_cols = ['orig_width', 'orig_height', 'orig_frames', 'orig_fps', \n",
        "                   'orig_n_colors', 'entropy', 'orig_kilobytes']\n",
        "    \n",
        "    available_features = [col for col in feature_cols if col in df.columns]\n",
        "    \n",
        "    if len(available_features) < 3:\n",
        "        print(f\"Need at least 3 features for clustering. Available: {available_features}\")\n",
        "        return None\n",
        "    \n",
        "    # Prepare data for clustering\n",
        "    cluster_data = df[available_features].copy()\n",
        "    \n",
        "    # Handle missing values\n",
        "    cluster_data = cluster_data.fillna(cluster_data.median())\n",
        "    \n",
        "    # Standardize features\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    scaled_data = scaler.fit_transform(cluster_data)\n",
        "    \n",
        "    # Perform K-means clustering\n",
        "    from sklearn.cluster import KMeans\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    cluster_labels = kmeans.fit_predict(scaled_data)\n",
        "    \n",
        "    # Add cluster labels to dataframe\n",
        "    df_clustered = df.copy()\n",
        "    df_clustered['cluster'] = cluster_labels\n",
        "    \n",
        "    print(f\"üìä Clustering Results ({n_clusters} clusters):\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # Analyze clusters\n",
        "    for cluster_id in range(n_clusters):\n",
        "        cluster_data = df_clustered[df_clustered['cluster'] == cluster_id]\n",
        "        print(f\"\\nüîç Cluster {cluster_id} ({len(cluster_data)} GIFs):\")\n",
        "        \n",
        "        if not cluster_data.empty:\n",
        "            for feature in available_features:\n",
        "                mean_val = cluster_data[feature].mean()\n",
        "                print(f\"   ‚Ä¢ Avg {feature}: {mean_val:.2f}\")\n",
        "    \n",
        "    # Visualize clusters using PCA\n",
        "    from sklearn.decomposition import PCA\n",
        "    \n",
        "    if len(available_features) >= 2:\n",
        "        pca = PCA(n_components=2)\n",
        "        pca_data = pca.fit_transform(scaled_data)\n",
        "        \n",
        "        plt.figure(figsize=(10, 8))\n",
        "        scatter = plt.scatter(pca_data[:, 0], pca_data[:, 1], \n",
        "                            c=cluster_labels, cmap='viridis', alpha=0.6)\n",
        "        plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
        "        plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
        "        plt.title('GIF Clusters (PCA Visualization)')\n",
        "        plt.colorbar(scatter, label='Cluster')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.show()\n",
        "        \n",
        "        print(f\"\\nüìà PCA Explained Variance:\")\n",
        "        print(f\"   ‚Ä¢ PC1: {pca.explained_variance_ratio_[0]:.1%}\")\n",
        "        print(f\"   ‚Ä¢ PC2: {pca.explained_variance_ratio_[1]:.1%}\")\n",
        "        print(f\"   ‚Ä¢ Total: {sum(pca.explained_variance_ratio_):.1%}\")\n",
        "    \n",
        "    return df_clustered\n",
        "\n",
        "if not gif_df.empty:\n",
        "    clustered_df = perform_clustering_analysis(gif_df, n_clusters=3)\n",
        "else:\n",
        "    print(\"üìù No data available for clustering analysis\")\n",
        "    clustered_df = None\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Advanced Analytics <a id=\"advanced\"></a>\n",
        "\n",
        "### Complexity Classification and Compression Recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_gif_complexity(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Classify GIFs by processing complexity based on characteristics.\"\"\"\n",
        "    if df.empty:\n",
        "        print(\"No data available for complexity classification\")\n",
        "        return df\n",
        "    \n",
        "    def calculate_complexity_score(row):\n",
        "        \"\"\"Calculate complexity score for a single GIF.\"\"\"\n",
        "        score = 0\n",
        "        \n",
        "        # Entropy contribution (0-40 points)\n",
        "        entropy = row.get('entropy', 0)\n",
        "        if entropy > 6:\n",
        "            score += 40\n",
        "        elif entropy > 4:\n",
        "            score += 25\n",
        "        else:\n",
        "            score += 10\n",
        "        \n",
        "        # Frame count contribution (0-30 points)\n",
        "        frames = row.get('orig_frames', 1)\n",
        "        if frames > 50:\n",
        "            score += 30\n",
        "        elif frames > 20:\n",
        "            score += 20\n",
        "        else:\n",
        "            score += 5\n",
        "        \n",
        "        # Dimension contribution (0-30 points)\n",
        "        pixels = row.get('pixels_total', 0)\n",
        "        if pixels > 500000:  # ~720p\n",
        "            score += 30\n",
        "        elif pixels > 200000:  # ~480p\n",
        "            score += 20\n",
        "        else:\n",
        "            score += 10\n",
        "        \n",
        "        return score\n",
        "    \n",
        "    # Calculate complexity scores\n",
        "    df_with_complexity = df.copy()\n",
        "    df_with_complexity['complexity_score'] = df.apply(calculate_complexity_score, axis=1)\n",
        "    \n",
        "    # Classify based on thresholds\n",
        "    def classify_complexity(score):\n",
        "        if score >= 80:\n",
        "            return 'high_complexity'\n",
        "        elif score >= 50:\n",
        "            return 'medium_complexity'\n",
        "        else:\n",
        "            return 'low_complexity'\n",
        "    \n",
        "    df_with_complexity['complexity_category'] = df_with_complexity['complexity_score'].apply(classify_complexity)\n",
        "    \n",
        "    # Analyze complexity distribution\n",
        "    complexity_counts = df_with_complexity['complexity_category'].value_counts()\n",
        "    \n",
        "    print(\"üìä Complexity Classification Results:\")\n",
        "    print(\"=\" * 40)\n",
        "    for category, count in complexity_counts.items():\n",
        "        percentage = (count / len(df_with_complexity)) * 100\n",
        "        print(f\"   ‚Ä¢ {category}: {count} GIFs ({percentage:.1f}%)\")\n",
        "    \n",
        "    # Visualize complexity distribution\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    \n",
        "    # Complexity distribution pie chart\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.pie(complexity_counts.values, labels=complexity_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "    plt.title('GIF Complexity Distribution')\n",
        "    \n",
        "    # Complexity score histogram\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(df_with_complexity['complexity_score'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "    plt.axvline(x=50, color='orange', linestyle='--', label='Medium threshold')\n",
        "    plt.axvline(x=80, color='red', linestyle='--', label='High threshold')\n",
        "    plt.xlabel('Complexity Score')\n",
        "    plt.ylabel('Number of GIFs')\n",
        "    plt.title('Complexity Score Distribution')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return df_with_complexity\n",
        "\n",
        "def generate_compression_recommendations(df: pd.DataFrame):\n",
        "    \"\"\"Generate compression parameter recommendations based on GIF characteristics.\"\"\"\n",
        "    if df.empty or 'complexity_category' not in df.columns:\n",
        "        print(\"No complexity data available for recommendations\")\n",
        "        return\n",
        "    \n",
        "    print(\"üéØ Compression Parameter Recommendations:\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    recommendations = {\n",
        "        'low_complexity': {\n",
        "            'description': 'Simple GIFs with low entropy, few frames, small dimensions',\n",
        "            'recommended_lossy': [0, 40],\n",
        "            'recommended_frame_ratios': [1.0, 0.8],\n",
        "            'recommended_colors': [256, 128],\n",
        "            'batch_size': 200,\n",
        "            'processing_priority': 'low'\n",
        "        },\n",
        "        'medium_complexity': {\n",
        "            'description': 'Moderate complexity GIFs with average characteristics',\n",
        "            'recommended_lossy': [0, 40, 80],\n",
        "            'recommended_frame_ratios': [1.0, 0.8, 0.6],\n",
        "            'recommended_colors': [256, 128, 64],\n",
        "            'batch_size': 100,\n",
        "            'processing_priority': 'medium'\n",
        "        },\n",
        "        'high_complexity': {\n",
        "            'description': 'Complex GIFs with high entropy, many frames, large dimensions',\n",
        "            'recommended_lossy': [0, 40],\n",
        "            'recommended_frame_ratios': [1.0, 0.8, 0.6, 0.4],\n",
        "            'recommended_colors': [256, 128, 64],\n",
        "            'batch_size': 50,\n",
        "            'processing_priority': 'high'\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    for category, rec in recommendations.items():\n",
        "        category_count = (df['complexity_category'] == category).sum()\n",
        "        print(f\"\\nüîç {category.upper()} ({category_count} GIFs):\")\n",
        "        print(f\"   Description: {rec['description']}\")\n",
        "        print(f\"   Recommended lossy levels: {rec['recommended_lossy']}\")\n",
        "        print(f\"   Recommended frame ratios: {rec['recommended_frame_ratios']}\")\n",
        "        print(f\"   Recommended color counts: {rec['recommended_colors']}\")\n",
        "        print(f\"   Optimal batch size: {rec['batch_size']}\")\n",
        "        print(f\"   Processing priority: {rec['processing_priority']}\")\n",
        "\n",
        "if not gif_df.empty:\n",
        "    # Classify complexity\n",
        "    gif_df_with_complexity = classify_gif_complexity(gif_df)\n",
        "    \n",
        "    # Generate recommendations\n",
        "    generate_compression_recommendations(gif_df_with_complexity)\n",
        "else:\n",
        "    print(\"üìù No data available for complexity analysis\")\n",
        "    gif_df_with_complexity = gif_df\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. Insights & Recommendations <a id=\"insights\"></a>\n",
        "\n",
        "### Summary of Key Findings and Actionable Recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_final_insights(df: pd.DataFrame, scan_results: Dict[str, Any]):\n",
        "    \"\"\"Generate final insights and recommendations based on analysis.\"\"\"\n",
        "    \n",
        "    print(\"üìã GIFLAB DATASET EXPLORATION - FINAL INSIGHTS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Dataset Overview Insights\n",
        "    print(\"\\nüîç DATASET OVERVIEW:\")\n",
        "    print(f\"   ‚Ä¢ Total GIF files discovered: {scan_results.get('total_files_found', 0)}\")\n",
        "    print(f\"   ‚Ä¢ Successfully analyzed: {len(df)} GIFs\")\n",
        "    print(f\"   ‚Ä¢ Corrupted/unreadable: {len(scan_results.get('corrupted_gifs', []))}\")\n",
        "    print(f\"   ‚Ä¢ Success rate: {scan_results.get('success_rate', 0):.1%}\")\n",
        "    \n",
        "    if not df.empty:\n",
        "        # Statistical Insights\n",
        "        print(\"\\nüìä KEY CHARACTERISTICS:\")\n",
        "        \n",
        "        if 'orig_kilobytes' in df.columns:\n",
        "            size_stats = df['orig_kilobytes'].describe()\n",
        "            print(f\"   ‚Ä¢ File sizes: {size_stats['min']:.1f} - {size_stats['max']:.1f} KB (avg: {size_stats['mean']:.1f} KB)\")\n",
        "        \n",
        "        if 'orig_width' in df.columns and 'orig_height' in df.columns:\n",
        "            common_widths = df['orig_width'].value_counts().head(3)\n",
        "            common_heights = df['orig_height'].value_counts().head(3)\n",
        "            print(f\"   ‚Ä¢ Common widths: {common_widths.index.tolist()}\")\n",
        "            print(f\"   ‚Ä¢ Common heights: {common_heights.index.tolist()}\")\n",
        "        \n",
        "        if 'orig_frames' in df.columns:\n",
        "            frame_stats = df['orig_frames'].describe()\n",
        "            print(f\"   ‚Ä¢ Frame counts: {frame_stats['min']:.0f} - {frame_stats['max']:.0f} (avg: {frame_stats['mean']:.1f})\")\n",
        "        \n",
        "        if 'orig_fps' in df.columns:\n",
        "            fps_stats = df['orig_fps'].describe()\n",
        "            print(f\"   ‚Ä¢ FPS range: {fps_stats['min']:.1f} - {fps_stats['max']:.1f} (avg: {fps_stats['mean']:.1f})\")\n",
        "        \n",
        "        # Complexity Distribution\n",
        "        if 'complexity_category' in df.columns:\n",
        "            complexity_dist = df['complexity_category'].value_counts()\n",
        "            print(f\"\\nüéØ COMPLEXITY DISTRIBUTION:\")\n",
        "            for category, count in complexity_dist.items():\n",
        "                percentage = (count / len(df)) * 100\n",
        "                print(f\"   ‚Ä¢ {category}: {count} GIFs ({percentage:.1f}%)\")\n",
        "    \n",
        "    # Actionable Recommendations\n",
        "    print(\"\\nüöÄ ACTIONABLE RECOMMENDATIONS:\")\n",
        "    print(\"\\n   üìà PROCESSING OPTIMIZATION:\")\n",
        "    print(\"      ‚Ä¢ Use complexity-based batching for parallel processing\")\n",
        "    print(\"      ‚Ä¢ Prioritize high-complexity GIFs for quality retention\")\n",
        "    print(\"      ‚Ä¢ Apply aggressive compression to low-complexity GIFs\")\n",
        "    \n",
        "    print(\"\\n   ‚öôÔ∏è  PARAMETER TUNING:\")\n",
        "    print(\"      ‚Ä¢ Low complexity: Focus on frame reduction and color optimization\")\n",
        "    print(\"      ‚Ä¢ Medium complexity: Balanced approach with moderate lossy compression\")\n",
        "    print(\"      ‚Ä¢ High complexity: Conservative lossy settings, preserve frames\")\n",
        "    \n",
        "    print(\"\\n   üîß PIPELINE OPTIMIZATION:\")\n",
        "    print(\"      ‚Ä¢ Implement resume functionality using GIF SHA hashes\")\n",
        "    print(\"      ‚Ä¢ Use metadata caching to avoid recomputation\")\n",
        "    print(\"      ‚Ä¢ Monitor processing time per complexity category\")\n",
        "    \n",
        "    print(\"\\n   üìä QUALITY THRESHOLDS:\")\n",
        "    print(\"      ‚Ä¢ Target SSIM > 0.9 for high-complexity GIFs\")\n",
        "    print(\"      ‚Ä¢ Accept SSIM > 0.8 for medium-complexity GIFs\")\n",
        "    print(\"      ‚Ä¢ Allow SSIM > 0.7 for low-complexity GIFs\")\n",
        "    \n",
        "    # Next Steps\n",
        "    print(\"\\nüìù NEXT STEPS:\")\n",
        "    print(\"   1. Implement seed JSON generation (notebook 02)\")\n",
        "    print(\"   2. Create complexity-based processing batches\")\n",
        "    print(\"   3. Develop parameter recommendation system\")\n",
        "    print(\"   4. Set up monitoring for processing performance\")\n",
        "    print(\"   5. Validate recommendations with compression results\")\n",
        "\n",
        "# Generate final insights\n",
        "generate_final_insights(gif_df_with_complexity if 'gif_df_with_complexity' in locals() else gif_df, scan_results)\n",
        "\n",
        "# Save analysis results for use in seed generation\n",
        "analysis_results = {\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'config': ANALYSIS_CONFIG,\n",
        "    'scan_results': {\n",
        "        'total_files_found': scan_results.get('total_files_found', 0),\n",
        "        'files_analyzed': scan_results.get('files_analyzed', 0),\n",
        "        'valid_gifs': len(scan_results.get('valid_gifs', [])),\n",
        "        'corrupted_gifs': len(scan_results.get('corrupted_gifs', [])),\n",
        "        'success_rate': scan_results.get('success_rate', 0)\n",
        "    }\n",
        "}\n",
        "\n",
        "if not gif_df.empty:\n",
        "    analysis_results['dataset_stats'] = {\n",
        "        'total_gifs_analyzed': len(gif_df),\n",
        "        'avg_file_size_kb': gif_df.get('orig_kilobytes', pd.Series()).mean(),\n",
        "        'avg_frames': gif_df.get('orig_frames', pd.Series()).mean(),\n",
        "        'avg_fps': gif_df.get('orig_fps', pd.Series()).mean(),\n",
        "        'complexity_distribution': gif_df.get('complexity_category', pd.Series()).value_counts().to_dict() if 'complexity_category' in gif_df.columns else {}\n",
        "    }\n",
        "\n",
        "# Save results to JSON for use in seed generation\n",
        "results_path = Path(\"../notebooks/exploration_results.json\")\n",
        "with open(results_path, 'w') as f:\n",
        "    json.dump(analysis_results, f, indent=2, default=str)\n",
        "\n",
        "print(f\"\\nüíæ Analysis results saved to: {results_path}\")\n",
        "print(\"\\n‚úÖ Dataset exploration complete! Ready for seed generation (notebook 02).\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üéûÔ∏è GifLab Dataset Exploration\n",
        "\n",
        "This notebook explores the raw GIF dataset and analyzes compression results.\n",
        "\n",
        "**TODO**: This will be implemented in Stage 10 (S10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "# GifLab imports\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "from giflab import meta, metrics\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Dataset Overview\n",
        "\n",
        "Load and examine the raw GIF files and compression results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Implement dataset exploration\n",
        "print(\"Dataset exploration notebook - to be implemented in Stage 10\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
