"""Command-line interface for GifLab."""

import multiprocessing
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional

import click

from .config import (
    CompressionConfig,
    PathConfig,
    DEFAULT_COMPRESSION_CONFIG,
    DEFAULT_PATH_CONFIG,
)
from .pipeline import CompressionPipeline


@click.group()
@click.version_option(version="0.1.0", prog_name="giflab")
def main():
    """üéûÔ∏è GifLab ‚Äî GIF compression and analysis laboratory."""
    pass


@main.command()
@click.argument(
    "raw_dir",
    type=click.Path(exists=True, file_okay=False, dir_okay=True, path_type=Path),
)
@click.option(
    "--workers",
    "-j",
    type=int,
    default=0,
    help=f"Number of worker processes (default: {multiprocessing.cpu_count()} = CPU count)",
)
@click.option(
    "--resume/--no-resume", default=True, help="Skip existing renders (default: true)"
)
@click.option(
    "--fail-dir",
    type=click.Path(file_okay=False, dir_okay=True, path_type=Path),
    help="Folder for bad GIFs (default: data/bad_gifs)",
)
@click.option(
    "--csv",
    type=click.Path(dir_okay=False, path_type=Path),
    help="Output CSV path (default: auto-date in data/csv/)",
)
@click.option("--dry-run", is_flag=True, help="List work only, don't execute")
@click.option(
    "--renders-dir",
    type=click.Path(file_okay=False, dir_okay=True, path_type=Path),
    help="Directory for rendered variants (default: data/renders)",
)
def run(
    raw_dir: Path,
    workers: int,
    resume: bool,
    fail_dir: Optional[Path],
    csv: Optional[Path],
    dry_run: bool,
    renders_dir: Optional[Path],
):
    """Run compression analysis on GIFs in RAW_DIR.

    Generates a grid of compression variants for every GIF and writes
    one CSV row per variant with quality metrics and metadata.

    RAW_DIR: Directory containing original GIF files to analyze
    """
    try:
        # Create path configuration
        path_config = PathConfig()

        # Override paths if provided
        if fail_dir:
            path_config.BAD_GIFS_DIR = fail_dir
        if renders_dir:
            path_config.RENDERS_DIR = renders_dir

        # Create compression pipeline
        pipeline = CompressionPipeline(
            compression_config=DEFAULT_COMPRESSION_CONFIG,
            path_config=path_config,
            workers=workers,
            resume=resume,
        )

        # Generate CSV path if not provided
        if csv is None:
            timestamp = datetime.now().strftime("%Y%m%d")
            csv = path_config.CSV_DIR / f"results_{timestamp}.csv"

        # Ensure CSV parent directory exists
        csv.parent.mkdir(parents=True, exist_ok=True)

        click.echo(f"üéûÔ∏è  GifLab Compression Pipeline")
        click.echo(f"üìÅ Input directory: {raw_dir}")
        click.echo(f"üìä Output CSV: {csv}")
        click.echo(f"üé¨ Renders directory: {path_config.RENDERS_DIR}")
        click.echo(f"‚ùå Bad GIFs directory: {path_config.BAD_GIFS_DIR}")
        click.echo(
            f"üë• Workers: {workers if workers > 0 else multiprocessing.cpu_count()}"
        )
        click.echo(f"üîÑ Resume: {'Yes' if resume else 'No'}")

        if dry_run:
            click.echo(f"üîç DRY RUN MODE - Analysis only")
            _run_dry_run(pipeline, raw_dir, csv)
        else:
            click.echo(f"üöÄ Starting compression pipeline...")
            _run_pipeline(pipeline, raw_dir, csv)

    except KeyboardInterrupt:
        click.echo(f"\n‚èπÔ∏è  Pipeline interrupted by user", err=True)
        sys.exit(1)
    except Exception as e:
        click.echo(f"‚ùå Pipeline failed: {e}", err=True)
        sys.exit(1)


def _run_dry_run(pipeline: CompressionPipeline, raw_dir: Path, csv_path: Path):
    """Run dry-run analysis showing what work would be done."""

    # Discover GIFs
    click.echo(f"\nüìã Discovering GIF files...")
    gif_paths = pipeline.discover_gifs(raw_dir)

    if not gif_paths:
        click.echo(f"‚ö†Ô∏è  No GIF files found in {raw_dir}")
        return

    click.echo(f"‚úÖ Found {len(gif_paths)} GIF files")

    # Generate jobs
    click.echo(f"\nüîß Generating compression jobs...")
    all_jobs = pipeline.generate_jobs(gif_paths)

    if not all_jobs:
        click.echo(f"‚ö†Ô∏è  No valid compression jobs could be generated")
        return

    # Filter existing jobs if resume is enabled
    jobs_to_run = pipeline.filter_existing_jobs(all_jobs, csv_path)

    # Show summary
    engines = DEFAULT_COMPRESSION_CONFIG.ENGINES
    frame_ratios = DEFAULT_COMPRESSION_CONFIG.FRAME_KEEP_RATIOS
    color_counts = DEFAULT_COMPRESSION_CONFIG.COLOR_KEEP_COUNTS
    lossy_levels = DEFAULT_COMPRESSION_CONFIG.LOSSY_LEVELS

    variants_per_gif = (
        len(engines) * len(frame_ratios) * len(color_counts) * len(lossy_levels)
    )

    click.echo(f"\nüìä Compression Matrix:")
    click.echo(f"   ‚Ä¢ Engines: {', '.join(engines)}")
    click.echo(f"   ‚Ä¢ Frame ratios: {', '.join(f'{r:.2f}' for r in frame_ratios)}")
    click.echo(f"   ‚Ä¢ Color counts: {', '.join(str(c) for c in color_counts)}")
    click.echo(f"   ‚Ä¢ Lossy levels: {', '.join(str(l) for l in lossy_levels)}")
    click.echo(f"   ‚Ä¢ Variants per GIF: {variants_per_gif}")

    click.echo(f"\nüìà Job Summary:")
    click.echo(f"   ‚Ä¢ Total jobs: {len(all_jobs)}")
    click.echo(f"   ‚Ä¢ Jobs to run: {len(jobs_to_run)}")
    click.echo(f"   ‚Ä¢ Jobs to skip: {len(all_jobs) - len(jobs_to_run)}")

    if len(jobs_to_run) == 0:
        click.echo(f"‚úÖ All jobs already completed")
    else:
        estimated_time = len(jobs_to_run) * 2  # Rough estimate: 2 seconds per job
        estimated_hours = estimated_time / 3600
        click.echo(
            f"‚è±Ô∏è  Estimated runtime: ~{estimated_time}s (~{estimated_hours:.1f}h)"
        )

    # Show sample jobs
    if jobs_to_run:
        click.echo(f"\nüìù Sample jobs to execute:")
        for i, job in enumerate(jobs_to_run[:5]):  # Show first 5 jobs
            click.echo(f"   {i+1}. {job.metadata.orig_filename}")
            click.echo(
                f"      ‚Ä¢ {job.engine}, lossy={job.lossy}, frames={job.frame_keep_ratio:.2f}, colors={job.color_keep_count}"
            )
            click.echo(f"      ‚Ä¢ Output: {job.output_path}")

        if len(jobs_to_run) > 5:
            click.echo(f"   ... and {len(jobs_to_run) - 5} more jobs")


def _run_pipeline(pipeline: CompressionPipeline, raw_dir: Path, csv_path: Path):
    """Execute the compression pipeline."""

    result = pipeline.run(raw_dir, csv_path)

    # Report results
    status = result["status"]
    processed = result["processed"]
    failed = result["failed"]
    skipped = result["skipped"]

    click.echo(f"\nüìä Pipeline Results:")
    click.echo(f"   ‚Ä¢ Status: {status}")
    click.echo(f"   ‚Ä¢ Processed: {processed}")
    click.echo(f"   ‚Ä¢ Failed: {failed}")
    click.echo(f"   ‚Ä¢ Skipped: {skipped}")

    if "total_jobs" in result:
        click.echo(f"   ‚Ä¢ Total jobs: {result['total_jobs']}")

    if "csv_path" in result:
        click.echo(f"   ‚Ä¢ Results saved to: {result['csv_path']}")

    if status == "completed":
        click.echo(f"‚úÖ Pipeline completed successfully!")
    elif status == "no_files":
        click.echo(f"‚ö†Ô∏è  No GIF files found to process")
    elif status == "no_jobs":
        click.echo(f"‚ö†Ô∏è  No valid compression jobs could be generated")
    elif status == "all_complete":
        click.echo(f"‚úÖ All jobs were already completed")
    elif status == "error":
        error_msg = result.get("error", "Unknown error")
        click.echo(f"‚ùå Pipeline failed: {error_msg}")
        sys.exit(1)
    else:
        click.echo(f"‚ö†Ô∏è  Pipeline completed with status: {status}")


@main.command()
@click.argument(
    "csv_file", type=click.Path(exists=True, dir_okay=False, path_type=Path)
)
def tag(csv_file: Path):
    """Add AI-generated tags to existing compression results.

    CSV_FILE: Path to results CSV file to add tags to
    """
    # Placeholder for S9 - tagging pass implementation
    click.echo(f"üè∑Ô∏è  Tagging pass not yet implemented")
    click.echo(f"üìÅ CSV file: {csv_file}")
    click.echo(f"‚è≥ This feature will be available in Stage 9")


if __name__ == "__main__":
    main()
